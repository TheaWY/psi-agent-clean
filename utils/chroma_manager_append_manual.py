import os, json, time
import openai, chromadb
from chromadb.config import Settings
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ChromaDB ì´ˆê¸°í™”
client = chromadb.PersistentClient(path="./chroma")
collection = client.get_or_create_collection("psi_chunks")

# ìˆ˜ë™ ì¸ì‚¬ì´íŠ¸ ë¡œë“œ
with open("./data/rag_chunks/psi_manual_insights.json", "r", encoding="utf-8") as f:
    manual_chunks = json.load(f)

# ê¸°ì¡´ ID ì¡°íšŒ (peek ì‚¬ìš©)
peeked = collection.peek(limit=10000)
existing_ids = set(peeked.get("ids", []))
print(f"ğŸ“¦ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë¬¸ì„œ ìˆ˜: {len(existing_ids)}ê°œ")

added_count = 0
for chunk in tqdm(manual_chunks, desc="â• ìƒˆ ë¬¸ì„œ ì¶”ê°€ ì¤‘"):
    if chunk["id"] in existing_ids:
        continue

    try:
        # âš ï¸ 3072ì°¨ì› ëª¨ë¸ ì‚¬ìš©
        emb = openai.Embedding.create(
            model="text-embedding-3-large",
            input=chunk["text"]
        )["data"][0]["embedding"]

        collection.add(
            ids=[chunk["id"]],
            documents=[chunk["text"]],
            metadatas=[{
                "source": "manual_insight",
                "keywords": ", ".join(chunk.get("keywords", []))
            }],
            embeddings=[emb]
        )
        added_count += 1
        print(f"âœ… ì¶”ê°€ ì„±ê³µ: {chunk['id']}")
    except Exception as e:
        print(f"âŒ ì‹¤íŒ¨: {chunk['id']} / {e}")
        time.sleep(1)

print(f"\nâœ… ìƒˆë¡œ ì¶”ê°€ëœ ë¬¸ì„œ ìˆ˜: {added_count}ê°œ")
